{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d857eae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# IMU Data Training\n",
    "## Pose-from-IMU+Altitude Training (MARID)\n",
    "\n",
    "Train a feedforward network to predict **z and orientation** (z, roll, pitch, yaw) from a single timestep of IMU + altitude.\n",
    "\n",
    "- **Input (11-D):** quaternion (4), gyro (3), linear acceleration (3), altitude (1)\n",
    "- **Output (4-D):** z, roll, pitch, yaw — the **targets** the network is trained to predict (ground truth from Gazebo in the .npz).\n",
    "- **Data:** `.npz` from `pose_estimator_logger` (keys: `imu_inputs`, `pose_targets`)\n",
    "\n",
    "**Usage:** Run cells in order. Upload your `.npz` when prompted (or set `data_path` to a Drive path). Training uses 80/20 train/val split, MSE loss, and reports per-output validation MSE for z, roll, pitch, yaw.\n",
    "\n",
    "# ROS: data collection (order of launch files and nodes)\n",
    "\n",
    "1. **Start simulation and localization** (one launch; provides `/imu_ekf`, `/barometer/altitude`, `/gazebo/odom`):\n",
    "   `ros2 launch marid_description gazebo.launch.py`\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86ffab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aaba3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Uploading The Data\n",
    "\n",
    "# Upload / path to data\n",
    "# Option A: Upload file in Colab (run cell, then click \"Choose Files\")\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # pick your .npz file\n",
    "data_path = list(uploaded.keys())[0]\n",
    "\n",
    "# Option B: If file is on Google Drive (uncomment and run mount first)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/marid_pose_imu_altitude_XXXX_chunk0000.npz'\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for name in uploaded.keys():\n",
    "    if not name.endswith('.npz'):\n",
    "        continue\n",
    "    data = np.load(name, allow_pickle=True)\n",
    "    X_list.append(data['imu_inputs'].astype(np.float32))\n",
    "    y_list.append(data['pose_targets'].astype(np.float32))\n",
    "\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "print(f'Combined: X {X.shape}, y {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7accc3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Normalize and Split Data\n",
    "\n",
    "# Compute mean and std per feature (axis=0) so all 11 inputs have similar scale for training\n",
    "X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n",
    "\n",
    "# Avoid division by zero: if a feature never changes (std ≈ 0), treat it as scale 1\n",
    "X_std[X_std < 1e-8] = 1.0\n",
    "\n",
    "# Standardize: subtract mean, divide by std (zero mean, unit variance per feature)\n",
    "X_norm = (X - X_mean) / X_std\n",
    "\n",
    "# Train/val 80-20 split \n",
    "n = len(X_norm)\n",
    "# Shuffle indices so train and val are random subsets (not first 80% vs last 20%)\n",
    "idx = np.random.permutation(n)\n",
    "split = int(0.8 * n)\n",
    "train_idx, val_idx = idx[:split], idx[split:]\n",
    "\n",
    "# Convert to PyTorch tensors: train set for learning, val set for checking generalization\n",
    "X_train = torch.tensor(X_norm[train_idx])\n",
    "y_train = torch.tensor(y[train_idx])\n",
    "X_val   = torch.tensor(X_norm[val_idx])\n",
    "y_val   = torch.tensor(y[val_idx])\n",
    "print(f'Train: {X_train.shape}, Val: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980cb30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Model and Optimizer\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(256, 4)\n",
    ")\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Reduce LR when val loss stops improving (factor=0.5 => halve LR, patience=epochs to wait)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31ff29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Training Loop\n",
    "\n",
    "epochs = 2000\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training mode: enables dropout/batch-norm training behavior and allows gradients to be computed\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass: run the model on training inputs to get predictions (batch of 4-D vectors)\n",
    "    pred = model(X_train)\n",
    "\n",
    "    # Loss: mean squared error between predictions and ground-truth targets (single scalar)\n",
    "    loss = loss_fn(pred, y_train)\n",
    "\n",
    "    # Backpropagation: clear old gradients, compute new ones from loss, then update weights\n",
    "    optimizer.zero_grad()   # Clear gradients from the previous step (PyTorch accumulates by default)\n",
    "    loss.backward()        # Compute gradients of loss w.r.t. all model parameters\n",
    "    optimizer.step()       # Update each parameter: param = param - lr * grad\n",
    "\n",
    "    # Store training MSE for this epoch (for plotting); .item() gets a Python float from the tensor\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # Validation: check how well the model generalizes to unseen data (no gradient updates)\n",
    "    model.eval()           # Eval mode: disables dropout etc., same behavior as at inference\n",
    "    with torch.no_grad():  # Disable gradient tracking to save memory and speed (we don't need gradients for val)\n",
    "        v_loss = loss_fn(model(X_val), y_val)\n",
    "    val_losses.append(v_loss.item())\n",
    "\n",
    "    scheduler.step(v_loss)\n",
    "\n",
    "    # Print progress every 20 epochs so we can monitor train vs val MSE without flooding the output\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}  Train MSE: {train_losses[-1]:.6f}  Val MSE: {val_losses[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad56d30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Plotting Results\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=False)\n",
    "\n",
    "ax1.plot(train_losses, 'r-', label='Train MSE', linewidth=0.8)\n",
    "ax1.plot(val_losses, 'b-', label='Val MSE', linewidth=0.8)\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "ax1.set_title('Full run')\n",
    "\n",
    "# Zoom on last part (last 50% of epochs)\n",
    "start = len(train_losses) // 2\n",
    "ax2.plot(range(start, len(train_losses)), train_losses[start:], 'r-', label='Train MSE', linewidth=0.8)\n",
    "ax2.plot(range(start, len(val_losses)), val_losses[start:], 'b-', label='Val MSE', linewidth=0.8)\n",
    "ax2.set_xlim(start, len(train_losses))\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MSE')\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "ax2.set_title('Zoom: second half')\n",
    "\n",
    "plt.suptitle('Pose-from-IMU+Altitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df13f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Per-output Validation MSE\n",
    "\n",
    "# Use inference mode: no dropout, batch norm in eval mode (same as when you deploy the model)\n",
    "model.eval()\n",
    "# No gradient tracking: we're only computing predictions, not training\n",
    "with torch.no_grad():\n",
    "    # Run the model on the full validation set and convert to NumPy for per-output math\n",
    "    y_val_pred = model(X_val).numpy()\n",
    "\n",
    "# Ground-truth validation targets as NumPy (same shape as y_val_pred: N x 4)\n",
    "y_val_np = y_val.numpy()\n",
    "\n",
    "# One label per output: z (m), roll/pitch/yaw (rad)\n",
    "labels = ['z', 'roll', 'pitch', 'yaw']\n",
    "\n",
    "# Per-output MSE: for each of the 4 outputs, average squared error over all validation samples.\n",
    "# This shows which output (z vs roll/pitch/yaw) the model predicts best or worst.\n",
    "for i in range(4):\n",
    "    mse = np.mean((y_val_np[:, i] - y_val_pred[:, i])**2)\n",
    "    print(f'{labels[i]}: MSE = {mse:.6f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
